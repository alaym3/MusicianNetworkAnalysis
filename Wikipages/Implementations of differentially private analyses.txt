{{redirect-distinguish|Pinq|Pink (disambiguation){{!}}Pink|Pinque (disambiguation){{!}}Pinque}}

Since the advent of [[differential privacy]], a number of systems supporting differentially private data analyses have been implemented and deployed.

== Research Projects and Prototypes ==
* PINQ: An API implemented in C#.<ref>{{cite journal |last1=McSherry |first1=Frank |title=Privacy integrated queries |journal=Communications of the ACM |date=1 September 2010 |volume=53 |issue=9 |pages=89–97 |doi=10.1145/1810891.1810916 |url=https://www.microsoft.com/en-us/research/wp-content/uploads/2010/08/networking.pdf}}</ref>

* Airavat: A [[MapReduce]]-based system implemented in Java hardened with SELinux-like access control.<ref>{{cite journal |last1=Roy |first1=Indrajit |last2=Setty |first2=Srinath T.V. |last3=Kilzer |first3=Ann |last4=Shmatikov |first4=Vitaly |last5=Witchel |first5=Emmett |title=Airavat: Security and Privacy for MapReduce |journal=Proceedings of the 7th Usenix Symposium on Networked Systems Design and Implementation (NSDI) |date=April 2010 |url=https://www.usenix.org/legacy/event/nsdi10/tech/full_papers/roy.pdf}}</ref>

* Fuzz: Time-constant implementation in Caml Light of a domain-specific language.<ref name="DP_under_fire">{{cite journal |last1=Haeberlen |first1=Andreas |last2=Pierce |first2=Benjamin C. |last3=Narayan |first3=Arjun |title=Differential Privacy Under Fire |journal=20th USENIX Security Symposium |date=2011}}</ref>

* GUPT: Implementation of the [[sample-and-aggregate]] framework.<ref>{{cite book|last1=Mohan |first1=Prashanth |last2=Thakurta |first2=Abhradeep |last3=Shi |first3=Elaine |author3-link= Elaine Shi |last4=Song |first4=Dawn |last5=Culler |first5=David E. |chapter=GUPT: Privacy Preserving Data Analysis Made Easy |title=Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data  |pages=349–360 |doi=10.1145/2213836.2213876}}</ref>

* <math>\epsilon</math>KTELO: A framework and system for answering linear counting queries.<ref>{{cite journal |last1=Zhang |first1=Dan |last2=McKenna |first2=Ryan |last3=Kotsogiannis |first3=Ios |last4=Hay |first4=Michael |last5=Machanavajjhala |first5=Ashwin |last6=Miklau |first6=Gerome |title=<math>\epsilon</math>KTELO: A Framework for Defining Differentially-Private Computations |journal=SIGMOD'18: 2018 International Conference on Management of Data |date=June 2018 |pages=115–130 |doi=10.1145/3183713.3196921|arxiv=1808.03555 }}</ref>

== Real-World Deployments ==

* OnTheMap: Interactive tool for exploration of US commute patterns.<ref>{{cite web |url=https://onthemap.ces.census.gov/ |title=OnTheMap}}</ref><ref>{{cite journal |last1=Machanavajjhala |first1=Ashwin |last2=Kifer |first2=Daniel |last3=Abowd |first3=John |last4=Gehrke |first4=Johannes |last5=Vilhuber |first5=Lars |title=Privacy: Theory meets Practice on the Map |journal=2008 IEEE 24th International Conference on Data Engineering |pages=277–286 |date=April 2008 |doi=10.1109/ICDE.2008.4497436|isbn=978-1-4244-1836-7 }}</ref>

* RAPPOR: Google Chrome telemetry implementing [https://en.wikipedia.org/wiki/User:99rebound/Local_differential_privacy?veaction=edit&preload=Template%3ADashboard.wikiedu.org_draft_template local differential privacy].<ref>{{cite web |last1=Erlingsson |first1=Úlfar |title=Learning statistics with privacy, aided by the flip of a coin |url=https://security.googleblog.com/2014/10/learning-statistics-with-privacy-aided.html}}</ref><ref>{{cite journal |last1=Erlingsson |first1=Úlfar |last2=Pihur |first2=Vasyl |last3=Korolova |first3=Aleksandra |title=RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response |url=https://archive.org/details/arxiv-1407.6981 |journal=Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security |date=November 2014 |pages=1054–1067 |doi=10.1145/2660267.2660348|bibcode=2014arXiv1407.6981E |arxiv=1407.6981 }}</ref>

* PSI (Ψ): A '''P'''rivate data '''S'''haring '''I'''nterface developed as part of the Harvard University Privacy Tools Project.<ref>{{cite web |last1=Gaboardi |first1=Marco |last2=Honaker |first2=James |last3=King |first3=Gary |last4=Nissim |first4=Kobbi |last5=Ullman |first5=Jonathan |last6=Vadhan |first6=Salil |last7=Murtagh |first7=Jack |title=PSI (Ψ): a Private data Sharing Interface |url=https://privacytools.seas.harvard.edu/publications/psipaper |date=June 2016}}</ref>

* iOS and macOS keyboard statistics with [[local differential privacy]].<ref>{{cite journal |last1=Differential Privacy Team |title=Learning with Privacy at Scale |journal=Apple Machine Learning Journal |date=December 2017 |volume=1 |issue=8 |url=https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html}}</ref>

* Application usage statistics in Microsoft Windows 10.<ref>{{cite journal |last1=Ding |first1=Bolin |last2=Kulkarni |first2=Janardhan |last3=Yekhanin |first3=Sergey |title=Collecting Telemetry Data Privately |journal=31st Conference on Neural Information Processing Systems |date=December 2017 |pages=3574–3583|bibcode=2017arXiv171201524D |arxiv=1712.01524 }}</ref>

* Flex: A SQL-based system developed for internal Uber analytics.<ref>{{cite web |last1=Tezapsidis |first1=Katie |title=Uber Releases Open Source Project for Differential Privacy |url=https://medium.com/uber-security-privacy/differential-privacy-open-source-7892c82c42b6 |date=Jul 13, 2017}}</ref><ref>{{cite journal |last1=Johnson |first1=Noah |last2=Near |first2=Joseph P. |last3=Song |first3=Dawn |title=Towards Practical Differential Privacy for SQL Queries |journal=Proceedings of the VLDB Endowment |date=January 2018 |volume=11 |issue=5 |pages=526–539 |doi=10.1145/3187009.3177733|arxiv=1706.09479 }}</ref>

* TensorFlow Privacy: An open-source library for differentially private  machine learning.<ref>{{cite web |last1=Radebaugh |first1=Carey |last2=Erlingsson |first2=Ulfar |title=Introducing TensorFlow Privacy: Learning with Differential Privacy for Training Data |url=https://medium.com/tensorflow/introducing-tensorflow-privacy-learning-with-differential-privacy-for-training-data-b143c5e801b6 |date=March 6, 2019}}</ref><ref>{{cite web |title=TensorFlow Privacy |url=https://github.com/tensorflow/privacy|date=2019-08-09}}</ref>

* Census 2020 synthetic microdata.<ref>{{cite journal |last1=Abowd |first1=John M. |title=The U.S. Census Bureau Adopts Differential Privacy |journal=Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining |date=August 2018 |page=2867 |doi=10.1145/3219819.3226070|isbn=9781450355520 |url=https://digitalcommons.ilr.cornell.edu/ldi/49 |hdl=1813/60392 |hdl-access=free }}</ref>

== Attacks on Implementations ==

In addition to standard defects of software artifacts that can be identified using [[Software testing|testing]] or [[fuzzing]], implementations of differentially private mechanisms may suffer from the following vulnerabilities:

* Subtle algorithmic or analytical mistakes.<ref>{{cite web |last1=McSherry |first1=Frank |title=Uber's differential privacy .. probably isn't |url=https://github.com/frankmcsherry/blog/blob/master/posts/2018-02-25.md |date=25 February 2018}}</ref><ref>{{cite journal |last1=Lyu |first1=Min |last2=Su |first2=Dong |last3=Li |first3=Ninghui |title=Understanding the sparse vector technique for differential privacy |journal=Proceedings of the VLDB Endowment |date=1 February 2017 |volume=10 |issue=6 |pages=637–648 |doi=10.14778/3055330.3055331|arxiv=1603.01699 }}</ref>

* Timing side-channel attacks.<ref name="DP_under_fire" /> In contrast with [[Timing_attack|timing attacks]] against implementations of cryptographic algorithms that typically have low leakage rate and must be followed with non-trivial cryptanalysis, a timing channel may lead to a catastrophic compromise of a differentially private system, since a targeted attack can be used to exfiltrate the very bit that the system is designed to hide.

* Leakage through floating-point arithmetic.<ref>{{cite journal |last1=Mironov |first1=Ilya |title=On Significance of the Least Significant Bits for Differential Privacy |journal=Proceedings of the 2012 ACM Conference on Computer and Communications Security (ACM CCS) |date=October 2012 |pages=650–661 |doi=10.1145/2382196.2382264 |publisher=ACM|url=https://www.microsoft.com/en-us/research/wp-content/uploads/2012/10/lsbs.pdf|isbn=9781450316514 }}</ref> Differentially private algorithms are typically presented in the language of probability distributions, which most naturally lead to implementations using floating-point arithmetic. The abstraction of floating-point arithmetic is [[leaky abstraction|leaky]], and without careful attention to details, a naive implementation may fail to provide differential privacy. (This is particularly the case for ε-differential privacy, which does not allow any probability of failure, even in the worst case.) For example, the support of a textbook sampler of the Laplace distribution (required, for instance, for the [[Additive_noise_mechanisms#Laplace_Mechanism|Laplace mechanism]]) is less than 80% of all [[Double-precision_floating-point_format|double-precision floating point numbers]]; moreover, the support for distributions with different means are not identical. A single sample from a naïve implementation of the Laplace mechanism allows distinguishing between two adjacent datasets with probability more than 35%.

* Timing channel through floating-point arithmetic.<ref>{{cite journal |last1=Andrysco |first1=Marc |last2=Kohlbrenner |first2=David |last3=Mowery |first3=Keaton |last4=Jhala |first4=Ranjit |last5=Lerner |first5=Sorin |last6=Shacham |first6=Hovav |title=On Subnormal Floating Point and Abnormal Timing |journal=2015 IEEE Symposium on Security and Privacy |date=May 2015 |pages=623–639 |doi=10.1109/SP.2015.44|isbn=978-1-4673-6949-7 }}</ref> Unlike operations over integers that are typically constant-time on modern CPUs, floating-point arithmetic exhibits significant input-dependent timing variability.<ref>{{cite journal |last1=Kohlbrenner |first1=David |last2=Shacham |first2=Hovav |title=On the Effectiveness of Mitigations Against Floating-point Timing Channels |journal=Proceedings of the 26th USENIX Conference on Security Symposium |date=August 2017 |pages=69–81 |publisher=USENIX Association}}</ref> Handling of [[Denormal_numbers|subnormals]] can be particularly slow, as much as by ×100 compared to the typical case.<ref>{{cite journal |last1=Dooley |first1=Isaac |last2=Kale |first2=Laxmikant |title=Quantifying the interference caused by subnormal floating-point values |journal=Proceedings of the Workshop on Operating System Interference in High Performance Applications |date=September 2006 |url=https://charm.cs.illinois.edu/newPapers/06-13/paper.pdf}}</ref>

== References ==
<references />

[[Category:Differential privacy]]   
[[Category:Information privacy]]